# Отчёт

### Итак, наша цель: исследовать, как поведут себя различные сортировки на практике при работе с разными видами и размерами массивов.

Оценивать будем по количеству времени выполнения программы (с точностью до наносекунды) и по количеству совершённых элементарных операций. 

Далее графики сгруппированы по 4 штуки на одно изображение для наглядности и удобства. 
Они расположены следующим образом:
```
- в верхнем левом углу график с результатами замеров времени для массивов размера 50 - 300
- в верхнем правом углу график с результатами замеров времени для массивов размера 100 - 4100
- в нижнем левом углу график с результатами замеров количества элементарных операций для массивов размера 50 - 300
- в нижнем правом углу график с результатами замеров количества элементарных операций для массивов размера 100 - 4100
```
Если какой-либо из графиков хочется рассмотреть ближе, стоит обратиться к папке [Graphs](https://github.com/kamilarakhimova/hse-algo-hw1/blob/main/Graphs), найти по названию и полюбоваться на него там.

Всего сортировок было 13 (+1), напомню каких:
```
1.    выбором
2.    пузырьком
3.    пузырьком с условием Айверсона 1
4.    пузырьком с условием Айверсона 2 
5.    простыми вставками
6.    бинарными вставками
7.    подсчетом (устойчивая)
8.    цифровой
9.    слиянием
10.   быстрой (первый опорный)
10.2  быстрой (средний опорный)
11.   пирамидальной
12.   Шелла (последовательность Циура)
13.   Шелла (последовательность Шелла)
```

Также было 4 вида массивов:
```
1.    заполненный рандомно сгенерированными числами от 0 до 5 
2.    заполненный рандомно сгенерированными числами от 0 до 4000
3.    с "почти" отсортированными в требуемом порядке числами (каждое 30-ое число поменялось местами с каждым 15-ым)
4.    с отсортированными в обратном порядке (по убыванию) числами от 4100 до 1
```

> Заранее замечу, что на графиках с замерами времени присутствует достаточно много выбросов. К сожалению, сколько я не пыталась с этим бороться, у меня не получилось сильнее сгладить линии и минимизировать выбросы. Полагаю, это связано с тем, что параллельно с записью получаемых данных в файл ".csv" происходило построение графиков в файлы ".png". Я решила оставить всё, как есть, ибо таковы последствия работы на практике, а не в теории, и они тоже своеобразно ценны и показательны.


Что ж, теперь начнём наш анализ с графиков каждой сортировки, прокомментируем их, а в конце уже перейдём к "общей картине".

1. Сортировка выбором (O(n^2))

![Selection Sort](https://user-images.githubusercontent.com/58568615/220103978-61eaf298-d727-4f06-9d56-2ea3e288150e.png)

Хоть сортировка выбором и считается одной из самых затратных по времени, мы можем заметить, что на маленьких размерах данных это почти не играет роли. Однако время, тратящееся на сортировку большого размера массивов резко возрастает по мере увеличения размера массива.
Зато любые массивы одинакового размера она сортирует примерно за одинаковое количество элементарных операций и времени. Судя по данным графика, вид сортируемого массива здесь особо не влияет на ассимптотику.

2. Сортировка пузырьком (O(n^2))

![Bubble Sort](https://user-images.githubusercontent.com/58568615/220120348-233df15b-561a-4234-ba61-b276012e3c6b.png)

Здесь сразу бросается в глаза, как сортировка пузырьком на порядок лучше справляется с сортировкой почти отсортированных и обратно отсортированных массивов, причём и по количеству проведённых элементарных операций, и по времени. Но в остальном она напоминает сортировку выбором [1]: также неплохо справляется с массивами небольших размеров и сильно хуже ассимптотически работает по мере возрастания размера массива. Труднее всего, как показывают почти все графики, ей обрабатывать массивы, заполненные числами из большого диапазона.

3. Сортировка пузырьком с условием Айверсона 1 (O(n^2))

![Bubble Sort Iverson 1](https://user-images.githubusercontent.com/58568615/220120286-7d495495-2d3a-4c00-83f1-67fb3a184fc0.png)

Данная сортировка является модификацией предыдущей сортировки [2]. Поэтому неудивительно, что во многом её результаты повторяют результаты обычной сортировки пузырьком [2]. Но это помогает нам наглядно увидеть, как улучшает работу сортировки [2] условие Айверсона 1. Ассимптотика сортировки при почти отсортированном и обратно отсортированном массиве стремится к линии O(n), что показывают все графики: и с замерами времени, и с замерами количества элементарных операций.

4. Сортировка пузырьком с условием Айверсона 2 (O(n^2))

![Bubble Sort Iverson 2](https://user-images.githubusercontent.com/58568615/220120321-e2c937e2-bbed-4f77-9bb1-3529d92fb2b7.png)

Здесь ситуация аналогична сортировке [3]. Правда, выглядит так, будто для почти отсортированного массива ассимптотика улучшилась ещё сильнее, стала более приближённой к линии. Как мы уже выяснили, сортировка пузырьком с любыми её модификациями [3-5] не дружит с массивами, заполненными рандомными числами, как и с массивами больших размеров. На них она не стесняясь показывает свою истинную ассимптотическую сущность: O(n^2).

5. Сортировка простыми вставками (O(n^2))

![Insertion Sort](https://user-images.githubusercontent.com/58568615/220120576-cf3021c5-382f-4687-be46-9c5f447e3b6c.png)

Результаты работы этой сортировки очень похожи на работу сортировки пузырьком. Тоже очень хорошая ассимптотика при работе с почти отсортированными и обратно отсортированными массивами, близкая к линии (O(n)), но проявляющая себя во всей красе при работе с рандомно сгенерированными массивами --> O(n^2). А также тратящая стремительно больше времени и количества элементарных операций с увеличением размера массива.

6. Сортировка бинарными вставками (O(n^2))

![Binary Insertion Sort](https://user-images.githubusercontent.com/58568615/220120267-6dfecbbc-453a-4354-9aef-c4b8b71ca6f0.png)

Данная сортировка является модификацией сортировки простыми вставками [5], снижающей ассимптотику поиска места для вставки элемента с O(n) на O(log(n)).
Первое, что бросается в глаза -- равное количество элементарных операций на одинаковых размерах данных при сортировке любого вида массива. Причём количество произведённых элементарных операций сильно меньше, нежели при предыдущей сортировке [5]. Бинарный поиск действительно помогает. В остальном ощутимых различий с результатами сортировки простыми вставками [5] не имеется.

7. Сортировка подсчетом (устойчивая) (O(n + k))

![Counting Sort](https://user-images.githubusercontent.com/58568615/220120376-ca65d7d6-53c9-483a-ae21-a43f627cae70.png)

Обратимся к линейным сортировкам. Графики подтверждают теоретическую базу: видно, что лучше всего сортировка подсчётом отрабатывает при небольшом диапазоне k, в нашем случве -- на массиве с маленьким диапазоном значений (0 - 5). А хуже всего она себя чувствует при работе с массивом, заполненным рандомно сгенерированными числами от 0 до 4000. При этом размер массива не так важен. И не наблюдается зависимости от того, почти отсортирован ли массив или обратно отсортирован, в обоих случаях результат примерно одинаковый.
Зато заметна большая разница по времени по сравнению с результатами работы предыдущих сортировок [1-6], в лучшую сторону.
При этом следует помнить, что для данной сортировки требуется дополнительная память в размере минимум O(k), если не трбуется устойчивость. А в случае устойчивой сортировки (как у нас) необходимо и O(n + k).

8. Цифровая сортировка (O(m(n + k)))

![Radix Sort](https://user-images.githubusercontent.com/58568615/220120473-13b178c7-acc5-4f87-9edd-500892c48046.png)

Время работы данной сортировки во многом зависит от количества разрядов в числе. Видно, что она, как и предыдущая сортировка [7], ведёт себя лучше на данных с небольшим диапазоном значений k и хуже на бОльших диапазонах. И также ускоряет свою работу, принося в жертву дополнительную память. Зато количество элементарных операций одинаково при любых видах массивов с одинаковым размером данных.
Хотя из представленных графиков сложно сделать такой вывод, из банального интереса, я запустила сортировку подсчётом [7] и цифровую сортировку на большом диапазоне значений k (с большей разрядностью m соответственно). Вот там действительно результаты показали, что сортировка [8] отрабатывает сильно быстрее, нежели сортировка [7].

9. Сортировка слиянием

![Merge Sort](https://user-images.githubusercontent.com/58568615/220120460-c092e225-b225-4d87-a4f7-cba855d009b3.png)

10. Быстрая сортировка (первый опорный)

![Quick Sort (first support)](https://user-images.githubusercontent.com/58568615/220120499-aa52be78-9742-41df-9e45-bd2355ba83ef.png)

11. Быстрая сортировка (средний опорный)

![Quick Sort (middle support)](https://user-images.githubusercontent.com/58568615/220120524-42dc2ded-f210-4253-b0e6-c44669500b66.png)

12. Пирамидальная сортировка

![Heap Sort](https://user-images.githubusercontent.com/58568615/220120610-e0b330b1-4e46-4e81-a1c3-93612903026f.png)

13. Сортировка Шелла (последовательность Циура)

![Shell Sort (Ciur sequence)](https://user-images.githubusercontent.com/58568615/220120404-56b1244f-e41f-4f5d-a70e-0dfbc22db69a.png)



14. Сортировка Шелла (последовательность Шелла)

![Shell Sort (Shell sequence)](https://user-images.githubusercontent.com/58568615/220120429-8ff33f08-675f-45c0-a9dd-a015189ea759.png)


Ну вот, мы рассмотрели все графики по отдельности.
Теперь сравним их работу "в общем", для каждого отдельного вида массива.

1. Массив, заполненный рандомно сгенерированными числами от 0 до 5

![From 0 to 5](https://user-images.githubusercontent.com/58568615/220121265-9deb0143-e4aa-4bb4-bd02-f630510a759b.png)

2. Массив, заполненный рандомно сгенерированными числами от 0 до 4000

![From 0 to 4000](https://user-images.githubusercontent.com/58568615/220121298-7099bffd-127f-40aa-bebc-b4a779b242e3.png)

3. Массив с "почти" отсортированными в требуемом порядке числами (каждое 30-ое число поменялось местами с каждым 15-ым)

![Almost sorted](https://user-images.githubusercontent.com/58568615/220121152-ee86e759-5388-4e98-9ca7-2c70ff73ed93.png)

4. Массив с отсортированными в обратном порядке (по убыванию) числами от 4100 до 1

![Reverse sorted](https://user-images.githubusercontent.com/58568615/220121186-30d050f5-5e22-4839-8069-ea5dd25c27c6.png)


### Вывод:

Подведём итоги исследования. Не существует однозначно лучшей сортировки. Выбирать какую использовать в конкретном случае следует исходя из множества факторов. Например, таких, как размер входных данных, случайность генерации данных, необходимая устойчивость/неустойчивость, требуемая ассимптотика, требуемые затраты на использование дополнительной памяти и пр. 
Так, сортировка Insertion sort [5], а лучше даже её модификация сортировка Binary Insertion Sort[6] скорее всего покажут себя эффективнее при вставка новых данных в уже отсортированную базу данных, нежели даже сортировки с меньшей теоретической ассимптотикой [7-12].
Однако в случае ...
